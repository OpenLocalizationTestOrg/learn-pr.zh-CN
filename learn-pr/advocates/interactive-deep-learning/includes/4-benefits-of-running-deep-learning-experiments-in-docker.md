![Docker 徽标](../media/3-image1.PNG)

<span data-ttu-id="51d54-102">Docker 是一种工具, 允许您在沙盒中部署应用程序, 以在所选的主机操作系统上运行。</span><span class="sxs-lookup"><span data-stu-id="51d54-102">Docker is a tool that allows you to deploy your applications in a sandbox to run on a host operating system of your choice.</span></span> <span data-ttu-id="51d54-103">它允许您使用标准化单元打包您的应用程序的所有依赖项。</span><span class="sxs-lookup"><span data-stu-id="51d54-103">It allows you to package your app with all of its dependencies in a standardized unit.</span></span> <span data-ttu-id="51d54-104">但是, 如果 DSVM 基本图像附带了已预安装的最热门的深入学习框架, 为什么要使用 Docker？</span><span class="sxs-lookup"><span data-stu-id="51d54-104">But if the DSVM base image comes with the most popular deep learning frameworks already pre-installed, why would you use Docker?</span></span>

<span data-ttu-id="51d54-105">尝试运行深入学习任务时, 开发人员会发现自己面临的依赖项问题。</span><span class="sxs-lookup"><span data-stu-id="51d54-105">When attempting to run deep learning tasks, developers find themselves facing dependency issues.</span></span> <span data-ttu-id="51d54-106">例如：</span><span class="sxs-lookup"><span data-stu-id="51d54-106">For example:</span></span> 

- <span data-ttu-id="51d54-107">必须构建自定义程序包-深入学习研究人员在将代码发布到 GitHub 时, 会更少地考虑生产。</span><span class="sxs-lookup"><span data-stu-id="51d54-107">Having to build custom packages - Deep learning researchers tend to think less about production when they publish code to GitHub.</span></span> <span data-ttu-id="51d54-108">如果他们能够获取在自己的开发环境中工作的包, 则通常只假定其他人也可以执行此操作。</span><span class="sxs-lookup"><span data-stu-id="51d54-108">If they can get a package working on their own development environment, they often just assume that others will be able to do so as well.</span></span>
- <span data-ttu-id="51d54-109">GPU 驱动程序版本控制-CUDA 是由 NVIDIA 开发的并行计算平台和应用程序编程接口 (API)。</span><span class="sxs-lookup"><span data-stu-id="51d54-109">GPU driver versioning - CUDA is a parallel computing platform and application programming interface (API) developed by NVIDIA.</span></span> <span data-ttu-id="51d54-110">它允许开发人员使用 CUDA 的图形处理单元 (GPU) 进行常规用途的处理。</span><span class="sxs-lookup"><span data-stu-id="51d54-110">It allows developers to use a CUDA-enabled graphics processing unit (GPU) for general-purpose processing.</span></span> <span data-ttu-id="51d54-111">某些版本的 Tensorflow 将无法与高于9.1 的 CUDA 版本一起使用。</span><span class="sxs-lookup"><span data-stu-id="51d54-111">Certain versions of Tensorflow will not work with versions of CUDA above 9.1.</span></span> <span data-ttu-id="51d54-112">其他框架 (如 PyTorch) 似乎更好地在更高版本的 CUDA 中运行。</span><span class="sxs-lookup"><span data-stu-id="51d54-112">Other frameworks, such as PyTorch, seem to perform better with later versions of CUDA.</span></span>

<span data-ttu-id="51d54-113">若要解决这些问题并提高代码的可用性, 可以使用 Docker 或其 GPU 型 NVIDIA Docker 来管理和运行深入学习项目。</span><span class="sxs-lookup"><span data-stu-id="51d54-113">To get around these issues and to increase the usability of code, you can use Docker or its GPU variant NVIDIA Docker to manage and run deep learning projects.</span></span> 

<!--Quiz 
What is CUDA? 
What versioning issues do deep learning engineers deal with? -->